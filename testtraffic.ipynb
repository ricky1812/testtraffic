{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23525 samples, validate on 7842 samples\n",
      "Epoch 1/10\n",
      "23525/23525 [==============================] - 379s 16ms/step - loss: 2.4439 - accuracy: 0.3337 - val_loss: 1.2463 - val_accuracy: 0.6143\n",
      "Epoch 2/10\n",
      "23525/23525 [==============================] - 424s 18ms/step - loss: 0.9895 - accuracy: 0.6922 - val_loss: 0.2792 - val_accuracy: 0.9124\n",
      "Epoch 3/10\n",
      "23525/23525 [==============================] - 415s 18ms/step - loss: 0.3645 - accuracy: 0.8851 - val_loss: 0.1082 - val_accuracy: 0.9671\n",
      "Epoch 4/10\n",
      "23525/23525 [==============================] - 399s 17ms/step - loss: 0.1944 - accuracy: 0.9384 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
      "Epoch 5/10\n",
      "23525/23525 [==============================] - 380s 16ms/step - loss: 0.1229 - accuracy: 0.9623 - val_loss: 0.0423 - val_accuracy: 0.9866\n",
      "Epoch 6/10\n",
      "23525/23525 [==============================] - 391s 17ms/step - loss: 0.0841 - accuracy: 0.9748 - val_loss: 0.0419 - val_accuracy: 0.9885\n",
      "Epoch 7/10\n",
      "23525/23525 [==============================] - 385s 16ms/step - loss: 0.0631 - accuracy: 0.9815 - val_loss: 0.0347 - val_accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "23525/23525 [==============================] - 404s 17ms/step - loss: 0.0524 - accuracy: 0.9830 - val_loss: 0.0371 - val_accuracy: 0.9901\n",
      "Epoch 9/10\n",
      "20368/23525 [========================>.....] - ETA: 53s - loss: 0.0334 - accuracy: 0.9883"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "#from scipy.misc import imread\n",
    "#from scipy import integrate\n",
    "#import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "import seaborn as sns\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "### LOADING DATASET\n",
    "data_dir = os.path.abspath('/home/rounak/AI/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images')\n",
    "os.path.exists(data_dir)\n",
    "\n",
    "### Function to resize the images using open cv\n",
    "def resize_cv(im):\n",
    "    return cv2.resize(im, (64, 64), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "### Loading datset\n",
    "list_images = []\n",
    "output = []\n",
    "for dir in os.listdir(data_dir):\n",
    "    if dir == '.DS_Store' :\n",
    "        continue\n",
    "    \n",
    "    inner_dir = os.path.join(data_dir, dir)\n",
    "    csv_file = pd.read_csv(os.path.join(inner_dir,\"GT-\" + dir + '.csv'), sep=';')\n",
    "    for row in csv_file.iterrows() :\n",
    "        img_path = os.path.join(inner_dir, row[1].Filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = img[row[1]['Roi.X1']:row[1]['Roi.X2'],row[1]['Roi.Y1']:row[1]['Roi.Y2'],:]\n",
    "        img = resize_cv(img)\n",
    "        list_images.append(img)\n",
    "        output.append(row[1].ClassId)\n",
    "\n",
    " \n",
    "### Plotting the dataset\n",
    "fig = sns.distplot(output, kde=False, bins = 43, hist = True, hist_kws=dict(edgecolor=\"black\", linewidth=2))\n",
    "fig.set(title = \"Traffic signs frequency graph\",\n",
    "        xlabel = \"ClassId\",\n",
    "        ylabel = \"Frequency\")\n",
    "\n",
    "input_array = np.stack(list_images)\n",
    "\n",
    "train_y = keras.utils.np_utils.to_categorical(output)\n",
    "\n",
    "### Randomizing the dataset\n",
    "randomize = np.arange(len(input_array))\n",
    "np.random.shuffle(randomize)\n",
    "x = input_array[randomize]\n",
    "y = train_y[randomize]\n",
    "\n",
    "### Splitting the dataset in train, validation, test set\n",
    "split_size = int(x.shape[0]*0.6)\n",
    "train_x, val_x = x[:split_size], x[split_size:]\n",
    "train1_y, val_y = y[:split_size], y[split_size:]\n",
    "\n",
    "split_size = int(val_x.shape[0]*0.5)\n",
    "val_x, test_x = val_x[:split_size], val_x[split_size:]\n",
    "val_y, test_y = val_y[:split_size], val_y[split_size:]\n",
    "\n",
    "\n",
    "### Building the model\n",
    "hidden_num_units = 2048\n",
    "hidden_num_units1 = 1024\n",
    "hidden_num_units2 = 128\n",
    "output_num_units = 43\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "pool_size = (2, 2)\n",
    "input_shape = Input(shape=(32, 32,3))\n",
    "\n",
    "model = Sequential([\n",
    "\n",
    " Conv2D(16, (3, 3), activation='relu', input_shape=(64,64,3), padding='same'),\n",
    " BatchNormalization(),\n",
    "\n",
    " Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    " BatchNormalization(),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    " Dropout(0.2),\n",
    "    \n",
    " Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    " BatchNormalization(),\n",
    "    \n",
    " Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    " BatchNormalization(),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    " Dropout(0.2),\n",
    "    \n",
    " Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    " BatchNormalization(),\n",
    "    \n",
    " Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    " BatchNormalization(),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    " Dropout(0.2),\n",
    "\n",
    " Flatten(),\n",
    "\n",
    " Dense(units=hidden_num_units, activation='relu'),\n",
    " Dropout(0.3),\n",
    " Dense(units=hidden_num_units1, activation='relu'),\n",
    " Dropout(0.3),\n",
    " Dense(units=hidden_num_units2, activation='relu'),\n",
    " Dropout(0.3),\n",
    " Dense(units=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "\n",
    "### Training the model\n",
    "trained_model_conv = model.fit(train_x.reshape(-1,64,64,3), train1_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))                               \n",
    "\n",
    "### Prdicting the class\n",
    "pred = model.predict_classes(test_x)\n",
    "\n",
    "### Evaluating the model\n",
    "model.evaluate(test_x, test_y)\n",
    "#view raw\n",
    "#Predicting-Traffic-Signs-using-CNN.py hosted with ‚ù§ by GitHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
